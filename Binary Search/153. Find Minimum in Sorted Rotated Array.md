## Binary Search Approach
The best explanation in my opinions is linked here, very detailed and logical explanation: https://www.youtube.com/watch?v=nIVW4P8b1VA
``` python
class Solution:
    def findMin(self, nums: List[int]) -> int:
        minVal = nums[0]
        l = 0
        r = len(nums) - 1

        while l <= r:
            m = (l + r) // 2
            minVal = min(minVal, nums[m])
            if nums[l] < nums[r]:
                minVal = min(minVal, nums[l])
                break
            # In the line below, the <= instead of < covers the edge case for [2,1]
            # because both l and m are at index 0, so the comparison 2 < 2 is false
            # but 2 <= 2 is true, which correctly searches the right half
            elif nums[l] <= nums[m]:
                l = m + 1
            else:
                r = m - 1

        return minVal
```
The time complexity is O(log(n)) in the worst case, since we are just doing a binary search with slightly different update conditions. The space complexity is O(1) in the worst case since we only use a few variables.

## Binary Search Approach (more optimized)
I find this approach better as it is cleaner logic and less code needed to be written. Basically, if m > right, we know that the minimum element is in the right half, because at some point in that right half the array goes from a larger value to a smaller value. Otherwise, from m to l, the array is sorted, so we know the element at m is the smallest in the right half, but we can't be sure that it is the smallest in the whole array, so we include it 