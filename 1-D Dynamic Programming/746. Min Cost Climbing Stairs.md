## Recursive Approach
For this approach, we can recursively calculate the min cost of getting to the top from the ith step. Logically, this means that we need to sum the cost of the ith step with the minimum cost to get there. If the ith position we are looking at is before the first step, in other words negative, we return zero as the step doesn't have a cost of its own, or a cost necessary to get to it. We also make sure to take the min of getting to the top step from the last two steps.
``` python
class Solution:
    def minCostClimbingStairs(self, cost: List[int]) -> int:
        def minCost(i):
            if i < 0:
                return 0
  
            return cost[i] + min(minCost(i-1), minCost(i-2))
  
        return min(minCost(len(cost) - 1), minCost(len(cost) - 2))
```
The time complexity is O(2^n) in the worst case since our recursion tree grows exponentially and we must calculate each and every value of the recursion tree, our time complexity is O(n) since our call stack only grows to at most n.
## Dynamic Programming Approach (Memoization)
The recursive approach has to calculate the result for same values multiple times, what if we stored those calculated values to avoid repeat recursive calls?
``` python
class Solution:
    def minCostClimbingStairs(self, cost: List[int]) -> int:
        calculated = {}
  
        def mincost(i):
            if i < 0:
                return 0
            if i in calculated:
                return calculated[i]
  
            calculated[i] = cost[i] + min(mincost(i - 1), mincost(i - 2))
            return calculated[i]
  
        return min(mincost(len(cost) - 1), mincost(len(cost) - 2))
```
The time complexity is O(n) in the worst case as we only make n calls to mincost and any repeat calls made by the exponentially recursive nature of the code don't need to be recalculated, the space complexity is also O(n) since our call stack only grows to at most n.
## Dynamic Programming Approach (Tabulation)
We are going to use an array/list to keep track of the minimum cost to get to step i (This array is going to have one more element than the input array, this is because we need to include the top floor, which was not included with the input array as it doesn't have a cost associated with it). To find the minimum cost to get to step i, we need to take the minimum of the cost to get to step i - 1 summed with the cost of step i - 1, and the cost to get to step i - 2 summed with the cost of step i - 2. After the whole array is filled in, we return the last element as this represents the cost to get to the top floor.
``` python
class Solution:
    def minCostClimbingStairs(self, cost: List[int]) -> int:
        arr = [0] * (len(cost) + 1)
  
        arr[0] = 0
        arr[1] = 0
  
        for i in range(2, len(arr)):
            arr[i] = min(cost[i - 1] + arr[i - 1], cost[i - 2] + arr[i - 2])
  
        return arr[-1]
```
The time complexity is going to be O(n) in the worst case since we would iterate through almost all n elements of the array when filling it in. The space complexity is going to be O(n) in the worst case since we create an array of size O(n).
## Dynamic Programming Approach (Space Optimized Tabulation)
Can we reduce the space complexity even further? The answer is yes! If we use the array which is passed into the function as an argument, we can reduce our space complexity to O(1) as we won't need to allocate any auxiliary memory. All it takes is a slight modification of our original tabulation solution, instead of the array at position i representing the min cost necessary to get to the ith position, we instead consider the array at position i to represent the min cost of getting to the top step (This is very similar in logic to our memoization approach!) Then we fill in the array from right to left, overriding the old values with our new values, and return the min of the two left-most elements.
``` python
class Solution:
    def minCostClimbingStairs(self, cost: List[int]) -> int:
        for i in range(len(cost) - 3, -1, -1):
            cost[i] += min(cost[i + 1], cost[i + 2])
        return min(cost[0], cost[1])
```
The time complexity is still O(n) in the worst case since we iterate through almost all elements of the array, but now the space complexity is O(1) since we are doing this in place, without the need of any extra memory allocated.